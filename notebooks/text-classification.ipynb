{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Templates for synthetic data generation\n",
    "infra_templates = [\n",
    "    \"Large pothole on {street} causing traffic disruptions\",\n",
    "    \"Broken streetlight at {location}\",\n",
    "    \"Cracked sidewalk tiles near {landmark}\",\n",
    "    \"Damaged road signs on {road}\",\n",
    "    \"Unfinished road construction blocking {area}\",\n",
    "    \"Flooded street near {location} after heavy rain\",\n",
    "    \"Collapsed drainage system in {area}\",\n",
    "    \"Illegal speed bump installed on {street}\",\n",
    "    \"Missing guardrails on {road} bridge\",\n",
    "    \"Graffiti covering traffic signs at {location}\"\n",
    "]\n",
    "\n",
    "sanitation_templates = [\n",
    "    \"Garbage pile-up near {landmark} for {days} days\",\n",
    "    \"Sewage overflow in {area} residential zone\",\n",
    "    \"Foul smell from uncollected waste near {location}\",\n",
    "    \"Trash cans overflowing at {landmark}\",\n",
    "    \"Stagnant water causing mosquito breeding in {area}\",\n",
    "    \"Animal carcass left unattended on {street}\",\n",
    "    \"Medical waste dumped near {location}\",\n",
    "    \"Industrial waste discharge into {water_body}\",\n",
    "    \"Public toilets unusable at {landmark}\",\n",
    "    \"Food waste attracting stray animals in {area}\"\n",
    "]\n",
    "\n",
    "safety_templates = [\n",
    "    \"Malfunctioning traffic signal at {intersection}\",\n",
    "    \"Unsafe electrical wiring near {location}\",\n",
    "    \"Stray dogs attacking pedestrians in {area}\",\n",
    "    \"Missing pedestrian crossing signs on {road}\",\n",
    "    \"Unlicensed street vendors blocking {location}\",\n",
    "    \"Fire hazard due to illegal parking at {landmark}\",\n",
    "    \"Broken staircase railing in {public_space}\",\n",
    "    \"Aggressive street harassment near {location}\",\n",
    "    \"Unprotected construction site at {area}\",\n",
    "    \"Expired fire extinguishers in {building}\"\n",
    "]\n",
    "\n",
    "other_templates = [\n",
    "    \"Noise pollution from {source} during night hours\",\n",
    "    \"Vandalism of public property at {location}\",\n",
    "    \"Unauthorized advertising hoardings in {area}\",\n",
    "    \"Abandoned vehicles on {street}\",\n",
    "    \"Illegal tree cutting near {landmark}\",\n",
    "    \"Public park benches removed from {location}\",\n",
    "    \"Unauthorized religious processions blocking {road}\",\n",
    "    \"Misuse of disability parking spots at {landmark}\",\n",
    "    \"Loudspeaker violations in {area}\",\n",
    "    \"Defaced historical monument at {location}\"\n",
    "]\n",
    "\n",
    "# Fillers for template placeholders\n",
    "locations = [\"Main Market\", \"Central Square\", \"Riverfront\", \"City Hospital\",\n",
    "            \"Tech Park\", \"Old Town\", \"Railway Station\", \"Bus Depot\",\n",
    "            \"Children's Park\", \"Government Colony\"]\n",
    "\n",
    "streets = [\"Oak Street\", \"Maple Avenue\", \"Pine Road\", \"Cedar Lane\",\n",
    "          \"Elm Boulevard\", \"Birch Circle\", \"Willow Drive\", \"Ash Terrace\"]\n",
    "\n",
    "landmarks = [\"City Hall\", \"Public Library\", \"Grand Hotel\", \"Sunrise Mall\",\n",
    "            \"Community Center\", \"Sports Stadium\", \"Central Park\"]\n",
    "\n",
    "# Generate synthetic data\n",
    "def generate_data(templates, label, num_samples=25):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        template = random.choice(templates)\n",
    "        entry = template.format(\n",
    "            street=random.choice(streets),\n",
    "            location=random.choice(locations),\n",
    "            landmark=random.choice(landmarks),\n",
    "            road=random.choice(streets),\n",
    "            area=random.choice([\"North Zone\", \"South Zone\", \"East Zone\", \"West Zone\"]),\n",
    "            days=random.randint(2, 7),\n",
    "            water_body=random.choice([\"Lake Victoria\", \"Green River\", \"City Canal\"]),\n",
    "            intersection=random.choice(streets) + \" & \" + random.choice(streets),\n",
    "            public_space=random.choice([\"Community Park\", \"Shopping Complex\", \"Metro Station\"]),\n",
    "            building=random.choice([\"City Hospital\", \"Public Library\", \"Town Hall\"]),\n",
    "            source=random.choice([\"construction\", \"late-night parties\", \"street performers\"])\n",
    "        )\n",
    "        data.append({\"text\": entry, \"label\": label})\n",
    "    return data\n",
    "\n",
    "# Generate dataset\n",
    "full_data = []\n",
    "full_data += generate_data(infra_templates, \"INFRASTRUCTURE\")\n",
    "full_data += generate_data(sanitation_templates, \"SANITATION\")\n",
    "full_data += generate_data(safety_templates, \"PUBLIC_SAFETY\")\n",
    "full_data += generate_data(other_templates, \"OTHER\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(full_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"../data/grievance_dataset.csv\", index=False)\n",
    "print(\"Dataset generated with 100 samples!\")"
   ],
   "id": "f43bce9266bd9be7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "label2id = {\n",
    "    \"INFRASTRUCTURE\": 0,\n",
    "    \"SANITATION\": 1,\n",
    "    \"PUBLIC_SAFETY\": 2,\n",
    "    \"OTHER\": 3\n",
    "}\n",
    "df[\"labels\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df[[\"text\", \"labels\"]])"
   ],
   "id": "4b5e6fbd65652c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Add labels to the tokenized output\n",
    "    tokenized[\"labels\"] = examples[\"labels\"]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ],
   "id": "6ba77ee98019fb1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(tokenized_dataset.features)",
   "id": "7c3633f7a0db0e67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Split dataset\n",
    "train_test = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Model initialization\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=4,\n",
    "    id2label={v: k for k, v in label2id.items()}\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test[\"train\"],\n",
    "    eval_dataset=train_test[\"test\"],\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ],
   "id": "4ba19bd84de0cf8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save model and tokenizer\n",
    "model.save_pretrained(\"../data/grievance_classifier\")\n",
    "tokenizer.save_pretrained(\"../data/grievance_classifier\")"
   ],
   "id": "e6c6b7697abfdb34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate\n",
    "results = trainer.evaluate()\n",
    "print(f\"Validation accuracy: {results['eval_loss']}\")\n",
    "\n",
    "# Inference Example\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "test_cases = [\n",
    "    \"Overflowing trash cans near the market\",\n",
    "    \"Cracked sidewalk tiles on Central Avenue\",\n",
    "    \"Unsafe electrical wires hanging low near playground\"\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    result = classifier(case)[0]\n",
    "    print(f\"Input: {case}\\nPredicted: {result['label']} (Confidence: {result['score']:.2f})\\n\")"
   ],
   "id": "f8db195824bca936",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
